{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f20773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "with open(\"train_qa.txt\",\"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911d3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\",\"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4aa152",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data+train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a8aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for story,ques,ans in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(ques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fe8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add(\"yes\")\n",
    "vocab.add(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0570babc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aed69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "367cc459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len = max([len(data[0])for data in all_data])\n",
    "max_story_len\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9633f2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ques_len = max([len(data[1])for data in all_data])\n",
    "max_ques_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04ae638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from keras) (1.23.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from keras) (0.10.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from keras) (3.10.0)\n",
      "Requirement already satisfied: namex in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: rich in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from optree->keras) (4.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398043c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (2.16.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (22.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.7)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\p.v.satyanarayana\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ae5954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement keras.preprocessing.text (from versions: none)\n",
      "ERROR: No matching distribution found for keras.preprocessing.text\n"
     ]
    }
   ],
   "source": [
    "pip install keras.preprocessing.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6df0f739",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.preprocessing.text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.preprocessing.text'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bdd407e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mTokenizer\u001b[49m(filters \u001b[38;5;241m=\u001b[39m [])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters = [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text,train_question_text,train_answers = [],[],[]\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)\n",
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e005ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b26915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data,word_index = tokenizer.word_index,\n",
    "                      max_story_len = max_story_len,max_ques_len = max_ques_len):\n",
    "    X = []\n",
    "    Xq = []\n",
    "    Y = []\n",
    "    for story,query,answer in data:\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        y[word_index[answer]] = 1\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    return(pad_sequences(X,maxlen = max_story_len),\n",
    "          pad_sequences(Xq,maxlen = max_ques_len),\n",
    "          np.array(Y))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528093e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train,query_train,answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test,query_test,answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4416f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1835f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_ques_len,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim = vocab_len,output_dim = 64))\n",
    "input_encoder_m.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d50c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim = vocab_len,output_dim = max_ques_len))\n",
    "input_encoder_c.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec579ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim = vocab_len,output_dim = 64,input_length = max_ques_len))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m,question_encoded],axes = (2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa02534",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match,input_encoded_c])\n",
    "response = Permute((2,1))(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response,question_encoded])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b214df",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_len)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d783f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation(\"softmax\")(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence,question],answer)\n",
    "model.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy',metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d9c6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a21425",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([inputs_train,query_train],answers_train,\n",
    "                   batch_size = 32,epochs = 20,\n",
    "                   validation_data = ([inputs_test,query_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a10533",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Model accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65762068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model\n",
    "model.save(\"Chatbot.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf822bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"chatbot.h5\")\n",
    "results = model.predict(([inputs_test,query_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fdaf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(results[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137bc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(\"Predicted answer:\",k)\n",
    "print(\"Probability:\",results[23][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55059bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = ' '.join(test_data[14][0])\n",
    "story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = ' '.join(test_data[14][1])\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[14][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(\"Predicted answer:\",k)\n",
    "print(\"Probability:\",results[23][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22717e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"Mary dropped the football . Sandra discarded apple in kitchen . Daniel went to the office . \"\n",
    "question = \"Is Daniel in the office ?\"\n",
    "mydata = [(story.split(),question.split(),\"yes\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a675f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_question,my_answer = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([my_story,my_question]))\n",
    "val_max = np.argmax(pred_results[0])\n",
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(\"Predicted answer:\",k)\n",
    "print(\"Probability:\",pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f9266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
